---
title: "DS421 Summer 2019 R Markdown Document"
author: "Katherine Rose Wolf"
date: "August 4, 2019"
output: html_document
---

```{r load libraries}

library(tidyverse)
library(praise)

praise()  # self-esteem boost

```


```{r create file structure}

# create raw data file
if(!dir.exists("raw_data")) {
  dir.create("raw_data")
}

if(!dir.exists("intermediate_data")) {
  dir.create("intermediate_data")
}

```


```{r download modeled air pollution data}

# download air pollution file .nc edition
download.file(
  url = "http://fizz.phys.dal.ca/~atmos/datasets/EST2019/GWRwSPEC_PM25_NA_201601_201612-RH35.nc", 
  destfile = 
    file.path(
      "raw_data", 
      "GWRwSPEC_PM25_NA_201601_201612-RH35.nc"
    )
  )

# download air pollution file .asc edition
download.file(
  url = "http://fizz.phys.dal.ca/~atmos/datasets/EST2019/GWRwSPEC_PM25_NA_201601_201612-RH35-NoNegs.asc.zip", 
  destfile = 
    file.path(
      "raw_data", 
      "GWRwSPEC_PM25_NA_201601_201612-RH35-NoNegs.asc.zip"
    )
  )

```



```{r download, read, and save school addresses}

# download school addresses
download.file(
  url = "https://www.cde.ca.gov/schooldirectory/report?rid=dl1&tp=txt", 
  destfile = 
    file.path(
      "raw_data", 
      "public_school_directory.rdata"
    )
  )

# read school addresses into tibble
public_school_directory <-
  read_delim(file =
               file.path(
                 "raw_data",
                 "public_school_directory.rdata"
                 ),
             delim = "\t"
             )

# save school addresses
save(
  public_school_directory, 
  file = 
    file.path(
      "intermediate_data", 
      "public_school_directory.rdata"
    )
)

```


```{r download school enrollment data}

# school enrollment data by racial/ethnic designation, gender, and grade

# make school enrollment raw downloader function
school_enrollment_raw_downloader <-
  function(start_year_numeric){
    end_year_chr <- 
      as.character(start_year_numeric + 1) %>%  # add 1 to the start year
      substr(3, 4)  # get only the last two digits
    
    start_year_chr <- 
      as.character(start_year_numeric)  # convert start year to numeric
    
    url_file <- 
      str_c("http://dq.cde.ca.gov/dataquest/dlfile/dlfile.aspx?cLevel=School&cYear=", 
            start_year_chr, 
            "-", 
            end_year_chr, 
            "&cCat=Enrollment&cPage=filesenr.asp")
    
    download.file(
      url = url_file, 
      destfile = 
        file.path(
          "raw_data", 
          str_c("school_enrollment_", 
                start_year_chr,
                "_", 
                end_year_chr, 
                "_raw.txt")
        )
    )
  }

# make vector of starting years 2009-2018
start_years <- 
  seq(
    from = 2009,
    to = 2018, 
    by = 1
  )

# download all the school files at once
map(
  .f = school_enrollment_raw_downloader, 
  .x = start_years
)

# make function to read them all into r from tab-delimited files
school_enrollment_tab_reader <- 
  function(start_year_numeric){
    
    end_year_chr <- 
      as.character(start_year_numeric + 1) %>% 
      substr(3, 4)  # get only the last two digits
    
    start_year_chr <- 
      as.character(start_year_numeric)
    
    file_name <- 
      str_c("school_enrollment_", 
            start_year_chr, 
            "_", 
            end_year_chr, 
            "_raw.txt")
      
    variable_name <- 
      str_c("school_enrollment_", 
            start_year_chr, 
            "_", 
            end_year_chr, 
            "_working")
    
    read_tibble <- 
      read_delim(
        file = 
          file.path(
            "raw_data", 
            file_name),
        delim = "\t"
        )
    
    assign(variable_name, 
           read_tibble)
    
    save(
      list = variable_name, 
      file = 
        file.path(
          "intermediate_data", 
          str_c(
            variable_name, 
            ".rdata"
          )
        )
    )
    
    # return(read_tibble)
  }

# use function on all files
map(
  .f = school_enrollment_tab_reader, 
  .x = start_years
)
  
```


```{r read school primary short enrollment data files, eval=FALSE, include=FALSE}

# make school primary short data file downloader function
school_primary_short_enrollment_raw_downloader <-
  function(start_year_numeric){
    end_year_chr <- 
      as.character(start_year_numeric + 1) %>%  # add 1 to the start year
      substr(3, 4)  # get only the last two digits
    
    start_year_chr <- 
      as.character(start_year_numeric) %>%   # convert start year to numeric
      substr(3, 4)  # get only the last two digits
    
    start_year_chr_long <- 
      as.character(start_year_numeric)
    
    url_file <- 
      str_c(
        "http://dq.cde.ca.gov/dataquest/dlfile/dlfile.aspx?cLevel=School&cYear=", 
        start_year_chr, 
        end_year_chr, 
        "&cCat=ShortTermEnrl&cPage=filesenrps.asp"
        )
            download.file(
      url = url_file, 
      destfile = 
        file.path(
          "raw_data", 
          str_c("school_primary_short_enrollment_", 
                start_year_chr_long,
                "_", 
                end_year_chr, 
                "_raw.txt")
        )
    )
  }

# make vector of starting years 2009-2018
start_years <- 
  seq(
    from = 2009,
    to = 2018, 
    by = 1
  )

# download all the school files at once
map(
  .f = school_primary_short_enrollment_raw_downloader, 
  .x = start_years
)

# make function to read them all into r from tab-delimited files
school_primary_short_enrollment_tab_reader <- 
  function(start_year_numeric){
    
    end_year_chr <- 
      as.character(start_year_numeric + 1) %>% 
      substr(3, 4)  # get only the last two digits
    
    start_year_chr <- 
      as.character(start_year_numeric)
    
    file_name <- 
      str_c("school_primary_short_enrollment_", 
            start_year_chr, 
            "_", 
            end_year_chr, 
            "_raw.txt")
      
    variable_name <- 
      str_c("school_primary_short_enrollment_", 
            start_year_chr, 
            "_", 
            end_year_chr, 
            "_working")
    
    read_tibble <- 
      read_delim(
        file = 
          file.path(
            "raw_data", 
            file_name),
        delim = "\t"
        )
    
    assign(variable_name, 
           read_tibble)
    
    save(
      list = variable_name, 
      file = 
        file.path(
          "intermediate_data", 
          str_c(
            variable_name, 
            ".rdata"
          )
        )
    )
    
    # return(read_tibble)
  }

# use function on all files
map(
  .f = school_primary_short_enrollment_tab_reader, 
  .x = start_years
)


```


```{r download raw 2017 facility emissions data, eval=FALSE, include=FALSE}

# download raw emissions csv file
download.file(
  url = "https://www.arb.ca.gov/app/emsinv/facinfo/faccrit_output.csv?&dbyr=2017&ab_=&dis_=&co_=&fname_=&city_=&sort=FacilityNameA&fzip_=&fsic_=&facid_=&all_fac=&chapis_only=&CERR=&dd=", 
  destfile = 
    file.path(
      "raw_data", 
      "facility_emissions_2017.csv"
    )
  )

facility_emissions_2017 <- 
  read_csv(file = 
             file.path(
               "raw_data",
               "facility_emissions_2017.csv"
               ), 
           col_types = 
             cols(CO = col_double(),
                  AB = col_character(),
                  FACID = col_double(),
                  DIS = col_character(),
                  FNAME = col_character(),
                  FSTREET = col_character(),
                  FCITY = col_character(),
                  FZIP = col_character(),
                  FSIC = col_double(),
                  COID = col_character(),
                  DISN = col_character(),
                  CHAPIS = col_character(),
                  CERR_CODE = col_character(),
                  TOGT = col_double(),
                  ROGT = col_double(),
                  COT = col_double(),
                  NOXT = col_double(),
                  SOXT = col_double(),
                  PMT = col_double(),
                  PM10T = col_double()))

# note: cannot read mapping file manually
facility_emissions_2017_mapping <- 
  read_csv(
    file = 
      file.path(
        "raw_data",
        "EmissionsByFacility.csv"
        ), 
    col_types = "cccccccccccccccccccccccccccccccccccccc"
    )

save(facility_emissions_2017_mapping, 
     file = 
       file.path(
         "intermediate_data", 
         "facility_emissions_2017_mapping.rdata"
       )
     )

colnames(facility_emissions_2017_mapping)

facility_emissions_2017_pm25 <- 
  facility_emissions_2017_mapping %>% 
  filter(!is.na(PM2.5))

nrow(facility_emissions_2017_pm25)

# facility_emissions_2017_mapping <- 
#   facility_emissions_2017_mapping %>% 
   

```


```{r monitor data}

monitor_urls <- 
  list()

monitor_urls$daily_pm25_monitors_2018 <- 
  "https://www.arb.ca.gov/aqmis2/display.php?download=y&param=PM25&units=001&year=2018&county_name=--COUNTY--&basin=--AIR+BASIN--&latitude=--PART+OF+STATE--&report=SITELIST&order=basin%2Ccounty_name%2Cs.name&submit=Retrieve+Data&ptype=aqd&std15="
  
monitor_urls$hourly_pm25_monitors_2018 <- 
  "https://www.arb.ca.gov/aqmis2/display.php?download=y&param=PM25HR&units=001&year=2018&county_name=--COUNTY--&basin=--AIR+BASIN--&latitude=--PART+OF+STATE--&report=SITELIST&order=basin%2Ccounty_name%2Cs.name&submit=Retrieve+Data&ptype=aqd&std15="

monitor_urls$daily_pm25_monitors_2017 <- 
  "https://www.arb.ca.gov/aqmis2/display.php?download=y&param=PM25&units=001&year=2017&county_name=--COUNTY--&basin=--AIR+BASIN--&latitude=--PART+OF+STATE--&report=SITELIST&order=basin%2Ccounty_name%2Cs.name&submit=Retrieve+Data&ptype=aqd&std15="
  
monitor_urls$hourly_pm25_monitors_2017 <- 
  "https://www.arb.ca.gov/aqmis2/display.php?download=y&param=PM25HR&units=001&year=2017&county_name=--COUNTY--&basin=--AIR+BASIN--&latitude=--PART+OF+STATE--&report=SITELIST&order=basin%2Ccounty_name%2Cs.name&submit=Retrieve+Data&ptype=aqd&std15="

monitor_urls$daily_pm25_monitors_2016 <- 
  "https://www.arb.ca.gov/aqmis2/display.php?download=y&param=PM25&units=001&year=2016&county_name=--COUNTY--&basin=--AIR+BASIN--&latitude=--PART+OF+STATE--&report=SITELIST&order=basin%2Ccounty_name%2Cs.name&submit=Retrieve+Data&ptype=aqd&std15="
  
monitor_urls$hourly_pm25_monitors_2016 <- 
  "https://www.arb.ca.gov/aqmis2/display.php?download=y&param=PM25HR&units=001&year=2016&county_name=--COUNTY--&basin=--AIR+BASIN--&latitude=--PART+OF+STATE--&report=SITELIST&order=basin%2Ccounty_name%2Cs.name&submit=Retrieve+Data&ptype=aqd&std15="
  
monitor_urls$daily_pm25_monitors_2015 <- 
    "https://www.arb.ca.gov/aqmis2/display.php?download=y&param=PM25&units=001&year=2015&county_name=--COUNTY--&basin=--AIR+BASIN--&latitude=--PART+OF+STATE--&report=SITELIST&order=basin%2Ccounty_name%2Cs.name&submit=Retrieve+Data&ptype=aqd&std15="
  
monitor_urls$hourly_pm25_monitors_2015 <- 
  "https://www.arb.ca.gov/aqmis2/display.php?download=y&param=PM25HR&units=001&year=2015&county_name=--COUNTY--&basin=--AIR+BASIN--&latitude=--PART+OF+STATE--&report=SITELIST&order=basin%2Ccounty_name%2Cs.name&submit=Retrieve+Data&ptype=aqd&std15="

# make function to download files
carb_pm25_monitor_raw_downloader <-
  function(monitor_url, 
           object_name){
    download.file(
      url = monitor_url, 
      destfile = 
        file.path(
          "raw_data", 
          str_c(object_name,
                "_raw.txt")
        )
    )
  }

# download files from the internet!
map2(
  .x = monitor_urls, 
  .y = names(monitor_urls),
  .f = carb_pm25_monitor_raw_downloader
)

# make function to read monitor files into r from csv
monitor_csv_to_tibble_reader <- 
  function(object_name){
    
    monitor_tibble <- 
      read_csv(
        file = 
          file.path(
            "raw_data", 
            str_c(
              object_name,
              "_raw.txt")
            )
      )
    
    assign(object_name, 
           monitor_tibble)
    
    save(
      list = object_name, 
      file = 
        file.path(
          "intermediate_data", 
          str_c(
            object_name, 
            ".rdata"
          )
        )
    )
    
    return(monitor_tibble)
  }

monitor_tibbles <- 
  map(
    .f = monitor_csv_to_tibble_reader, 
    .x = names(monitor_urls)
  )

# name the resulting tibbles
names(monitor_tibbles) <- 
  names(monitor_urls)

# focus on 2017
daily_pm25_monitors_2017 <- 
  monitor_tibbles$daily_pm25_monitors_2017
hourly_pm25_monitors_2017 <- 
  monitor_tibbles$hourly_pm25_monitors_2017

# get number of rows with text signaling the end of the data
data_end_daily_2017 <- 
  which(
    grepl(
      "Quality Flag Definition", 
      daily_pm25_monitors_2017$basin
    )
  ) - 1

data_end_hourly_2017 <- 
  which(
    grepl(
      "Quality Flag Definition", 
      hourly_pm25_monitors_2017$basin
    )
  ) - 1

# remove those rows
daily_pm25_monitors_2017_working <- 
  daily_pm25_monitors_2017 %>% 
  slice(1:data_end_daily_2017)

hourly_pm25_monitors_2017_working <- 
  hourly_pm25_monitors_2017 %>% 
  slice(1:data_end_hourly_2017)

# find monitors in common
intersect(daily_pm25_monitors_2017_working$aqs_id, 
          hourly_pm25_monitors_2017_working$aqs_id)

# fix the monitors for putting together hourlies and dailies
daily_pm25_monitors_2017_working <-
  daily_pm25_monitors_2017_working %>% 
  mutate(observations = pm25daily2017obs, 
         frequency = "daily") %>% 
  select(-pm25daily2017obs)

hourly_pm25_monitors_2017_working <- 
  hourly_pm25_monitors_2017_working %>% 
  mutate(observations = pm25hourly2017obs, 
         frequency = "hourly") %>% 
  select(-pm25hourly2017obs)

colnames(daily_pm25_monitors_2017_working) ==
  colnames(hourly_pm25_monitors_2017_working)

pm_25_monitors_overall <- 
  daily_pm25_monitors_2017_working %>% 
  bind_rows(hourly_pm25_monitors_2017_working)

```

```{r latitude and longitude}



```

