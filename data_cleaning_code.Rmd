---
title: "Causal Inference Final Project Code"
author: "Katherine Rose Wolf"
date: "March 27, 2020"
output: html_document
---

```{r setup load libraries}

library(praise)
library(raster)
library(tigris)
library(sf)
library(httr)
library(tidyverse)
library(ggmap)
library(nngeo)
library(tableone)
library(kableExtra)
library(furniture)
library(RColorBrewer)

# stop r from abbreviating doubles in school ids
options("scipen" = 40)

praise()  # self-esteem boost

# set encrypted google api key
register_google(key = Sys.getenv("hidden_google_api_key"))

```


```{r create file structure}

# create raw data file
if(!dir.exists("raw_data")) {
  dir.create("raw_data")
}

if(!dir.exists("intermediate_data")) {
  dir.create("intermediate_data")
}

if(!dir.exists("functions")) {
  dir.create("functions")
}

```


```{r functions for general later use}

# function to convert column names to snake case
column_name_fixer <-
  function(tibble) {
  new_names <-
    tibble %>%
    colnames() %>%  # gets the column names from the tibble
    tolower() %>%  # converts the column names to lowercase
    {gsub(" ", "_", .)}  # replaces spaces with "_"
  colnames(tibble) <-
    new_names  # rename the columns in the original tibble
  return(tibble)
  }

# create function that downloads files
file_downloader <-
  function(desired_filename_as_string, 
           web_address_as_string, 
           folder_as_string) {
    
    path <-  # specify the file path
      file.path(
        folder_as_string,
        desired_filename_as_string) 
    
    if(!file.exists(path))  # checks if file exists already
      download.file(url = web_address_as_string,  # if not, downloads/saves file
                    destfile = path, 
                    mode = "wb")
  }

# save functions for later use
save(
  column_name_fixer, 
     file = 
       file.path(
         "functions", 
         "column_name_fixer.rdata"
       )
)

save(
  file_downloader, 
     file = 
       file.path(
         "functions", 
         "file_downloader.rdata"
       )
)

# remove all objects from the environment
rm(list = ls(all.names = TRUE))

```


# raw data downloads

## modeled pm2.5

```{r download modeled air pollution data}

# download 2018 pm2.5 air pollution file .nc edition
if(!file.exists(file.path("raw_data", 
                          "GWRwSPEC.HEI_PM25_NA_201801_201812-RH35.nc"))) {

  download.file(
    url = "http://fizz.phys.dal.ca/~atmos/datasets/EST2019/GWRwSPEC.HEI_PM25_NA_201801_201812-RH35.nc", 
    destfile = 
      file.path(
        "raw_data", 
        "GWRwSPEC.HEI_PM25_NA_201801_201812-RH35.nc"
      ), 
    method = 'libcurl'
    )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))

}

# download 2018 pm2.5 air pollution file .asc edition
if(!file.exists(file.path("raw_data", 
                          "GWRwSPEC.HEI_PM25_NA_201801_201812-RH35-NoNegs.asc.zip"))) {
  
  download.file(
    url = "http://fizz.phys.dal.ca/~atmos/datasets/EST2019/GWRwSPEC.HEI_PM25_NA_201801_201812-RH35-NoNegs.asc.zip", 
    destfile = 
      file.path(
        "raw_data", 
        "GWRwSPEC.HEI_PM25_NA_201801_201812-RH35-NoNegs.asc.zip"
      ), 
    method = 'libcurl'
    )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))
  
}

```

## geographic shapefiles

```{r load united states state shapefiles}

# download the united states border shapefiles
if(!file.exists(file.path("raw_data", 
                          "state_shapefiles.rdata"))) {
  
  # states() is a tigris function
  state_shapefiles <- 
    states(
            cb = FALSE,  # downloads detailed outlines
            year = 2017, 
            class = 'sf'  # requests sf format to play nicely with sf package
          )
  
  # save raw file to disk
  save(
    state_shapefiles, 
    file = 
      file.path(
        "raw_data", 
        "state_shapefiles.rdata"
      )
  )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))
}

```


```{r air district boundaries}

# download air district boundary shapefiles
if(!file.exists(file.path("raw_data", 
                          "california-air-resources-board-air-district-boundaries.zip"))) {
  
  download.file(
    url = "https://data.ca.gov/dataset/d16bdc45-5f0d-4b68-9a82-f39731bcae61/resource/c1b45bcd-fd05-4cb5-bd63-7640c8fca0a6/download/california-air-resources-board-air-district-boundaries.zip", 
    destfile = 
      file.path(
        "raw_data", 
        "california-air-resources-board-air-district-boundaries.zip"
      ), 
    method = 'libcurl'
    )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))
  
}

```


```{r air basin boundaries}

if(!file.exists(file.path("raw_data", 
                          "california-air-resources-board-air-basin-boundaries.zip"))) {
  
  download.file(
    url = "https://data.ca.gov/dataset/d16bdc45-5f0d-4b68-9a82-f39731bcae61/resource/7884fbab-f309-48b3-81bd-e8cd6106693f/download/california-air-resources-board-air-basin-boundaries.zip", 
    destfile = 
      file.path(
        "raw_data", 
        "california-air-resources-board-air-basin-boundaries.zip"
      ), 
    method = 'libcurl'
    )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))
  
}

```


## school enrollment

```{r download school enrollment data}

# school enrollment data by racial/ethnic designation, gender, and grade

if(!file.exists(file.path("raw_data", 
                          "school_enrollment_2018_19_raw.txt"))) {

  # make school enrollment raw downloader function
  school_enrollment_raw_downloader <-
    function(start_year_numeric){
      end_year_chr <- 
        as.character(start_year_numeric + 1) %>%  # add 1 to the start year
        substr(3, 4)  # get only the last two digits
      
      start_year_chr <- 
        as.character(start_year_numeric)  # convert start year to numeric
      
      url_file <- 
        str_c("http://dq.cde.ca.gov/dataquest/dlfile/dlfile.aspx?cLevel=School&cYear=", 
              start_year_chr, 
              "-", 
              end_year_chr,
              "&cCat=Enrollment&cPage=filesenr.asp")
      
      # GET(
      #   url = url_file, 
      #   write_disk = 
      #     file.path(
      #       "raw_data", 
      #       str_c("school_enrollment_", 
      #             start_year_chr,
      #             "_", 
      #             end_year_chr, 
      #             "_raw.txt")
      #     ), 
      #   overwrite = TRUE
      # )
      
      download.file(url = url_file, 
                    destfile = file.path(
                      "raw_data", 
                      str_c("school_enrollment_", 
                            start_year_chr,
                            "_", 
                            end_year_chr, 
                            "_raw.txt")
                      ), 
                    method = 'libcurl'
                    )
      
      Sys.sleep(time = 5)  # pause to try to avoid anti-scraping blocker
    }
  
  # make vector of starting years 2015-2018
  start_years <- 
    seq(
      from = 2018,
      to = 2018, 
      by = 1
    )
  
  # download all the school files at once
  map(
    .f = school_enrollment_raw_downloader, 
    .x = start_years
  )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))

}

```

## school addresses

```{r download school addresses}

# download school addresses

if(!file.exists(file.path("raw_data", 
                          "public_school_directory.txt"))) {
  GET(
    url = "https://www.cde.ca.gov/schooldirectory/report?rid=dl1&tp=txt", 
    write_disk(
      file.path(
        "raw_data",
        "public_school_directory.txt"
      ),
      overwrite = TRUE
      )
    )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))
}

```


## school full-time equivalents

```{r download school fte data}

# download teaching credential data 2018-19
if(!file.exists(file.path("raw_data", 
                          "StaffSchoolFTE18.txt"))) {
download.file(
  url = "ftp://ftp.cde.ca.gov/demo/staffclass/StaffSchoolFTE18.txt", 
  destfile = 
    file.path(
      "raw_data", 
      "StaffSchoolFTE18.txt"
    ), 
  method = 'libcurl'
  )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))
}

```



## teaching credentials

```{r download teaching credential data}

# download teaching credential data 2018-19
if(!file.exists(file.path("raw_data", 
                          "StaffCred18.txt"))) {
download.file(
  url = "ftp://ftp.cde.ca.gov/demo/staffclass/StaffCred18.txt", 
  destfile = 
    file.path(
      "raw_data", 
      "StaffCred18.txt"
    ), 
  method = 'libcurl'
  )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))
}

```

## per-pupil funding

```{r download per-pupil funding data}

# download poverty data 2018-19
if(!file.exists(file.path("raw_data", 
                          "currentexpense1819.xlsx"))) {

  download.file(
    url = "https://www.cde.ca.gov/ds/fd/ec/documents/currentexpense1819.xlsx", 
    destfile = 
      file.path(
        "raw_data", 
        "currentexpense1819.xlsx"
      ), 
    mode = 'wb'
    )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))

}

```


## english learner data

```{r download english learner data}

if(!file.exists(file.path("raw_data", 
                          "fileselsch.txt"))) {
download.file(
  url = "http://dq.cde.ca.gov/dataquest/dlfile/dlfile.aspx?cLevel=School&cYear=2018-19&cCat=EL&cPage=fileselsch", 
  destfile = 
    file.path(
      "raw_data", 
      "fileselsch.txt"
    ), 
  method = 'libcurl'
  )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))
}

```



## free and reduced price lunch data

```{r download free and reduced price lunch data}

# download poverty data 2018-19
if(!file.exists(file.path("raw_data", 
                          "frpm1819.xlsx"))) {

  download.file(
    url = "https://www.cde.ca.gov/ds/sd/sd/documents/frpm1819.xlsx", 
    destfile = 
      file.path(
        "raw_data", 
        "frpm1819.xlsx"
      ), 
    mode = 'wb'
    )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))

}

```

## testing assessment data

```{r download english and mathematics testing assessment data}

# download english and mathematics individual student? data 2018-19
if(!file.exists(file.path("raw_data", 
                          "sb_ca2019_1_csv_v4.zip"))) {

  download.file(
    url = "http://caaspp-elpac.cde.ca.gov/caaspp/researchfiles/sb_ca2019_1_csv_v4.zip", 
    destfile = 
      file.path(
        "raw_data", 
        "sb_ca2019_1_csv_v4.zip"
      ), 
    mode = 'wb'
    )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))

}


# download english and mathematics group? data 2018-19
if(!file.exists(file.path("raw_data", 
                          "sb_ca2019_all_csv_v4.zip"))) {

  download.file(
    url = "http://caaspp-elpac.cde.ca.gov/caaspp/researchfiles/sb_ca2019_all_csv_v4.zip", 
    destfile = 
      file.path(
        "raw_data", 
        "sb_ca2019_all_csv_v4.zip"
      ), 
    mode = 'wb'
    )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))

}

```


```{r download science testing assessment data}


# download science individual student? data 2018-19
if(!file.exists(file.path("raw_data", 
                          "cast_ca2019_1_csv_v1.zip"))) {

  download.file(
    url = "http://caaspp-elpac.cde.ca.gov/caaspp/researchfiles/cast_ca2019_1_csv_v1.zip", 
    destfile = 
      file.path(
        "raw_data", 
        "cast_ca2019_1_csv_v1.zip"
      ), 
    mode = 'wb'
    )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))

}


# download science group? data 2018-19
if(!file.exists(file.path("raw_data", 
                          "cast_ca2019_all_csv_v1.zip"))) {

  download.file(
    url = "http://caaspp-elpac.cde.ca.gov/caaspp/researchfiles/cast_ca2019_all_csv_v1.zip", 
    destfile = 
      file.path(
        "raw_data", 
        "cast_ca2019_all_csv_v1.zip"
      ), 
    mode = 'wb'
    )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))

}


```


## chronic absenteeism data

```{r download chronic absenteeism data}

# download chronic absenteeism data 2018-19
if(!file.exists(file.path("raw_data", 
                          "chrabs1819.txt"))) {
download.file(
  url = "ftp://ftp.cde.ca.gov/demo/attendance/chrabs1819.txt", 
  destfile = 
    file.path(
      "raw_data", 
      "chrabs1819.txt"
    ), 
  method = 'libcurl'
  )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))
}

```



## suspension data

```{r download suspension data}

# download suspension data 2018-19
if(!file.exists(file.path("raw_data", 
                          "susp1819.txt"))) {
download.file(
  url = "ftp://ftp.cde.ca.gov/demo/discipline/susp1819.txt", 
  destfile = 
    file.path(
      "raw_data", 
      "susp1819.txt"
    ), 
  method = 'libcurl'
  )
  
  # remove all objects from the environment
  rm(list = ls(all.names = TRUE))
}

```



# data preparation

## pm2.5 data

```{r read modeled air pollution data into r}

# unzip the air pollution data file
unzip(
  zipfile = 
    file.path(
      "raw_data", 
      "GWRwSPEC.HEI_PM25_NA_201801_201812-RH35-NoNegs.asc.zip"
    ), 
  exdir = 
    file.path(
      "intermediate_data"
    )
  )

# check the file type
gdal_utils(
  util = "info",
  file.path(
      "intermediate_data", 
      "GWRwSPEC.HEI_PM25_NA_201801_201812-RH35-NoNegs.asc"
    )
)  # yup, just one band

# create the working raster
asc_air_data <- 
  raster(
    file.path(
      "intermediate_data", 
      "GWRwSPEC.HEI_PM25_NA_201801_201812-RH35-NoNegs.asc"
    )
  )
  
# save air data raster
save(
  asc_air_data, 
  file = 
    file.path(
      "intermediate_data", 
      "asc_air_data.rdata"
    )
)

# remove all objects from the environment
rm(list = ls(all.names = TRUE))

```


```{r air district boundary data}

# load asc air data to get crs
load(
  file = 
    file.path(
      "intermediate_data", 
      "asc_air_data.rdata"
    )
)

# unzip air district boundary data
unzip(
  zipfile = 
    file.path(
      "raw_data", 
      "california-air-resources-board-air-district-boundaries.zip"
    ), 
  exdir = 
    file.path(
      "intermediate_data"
    )
  )

# read it into r
air_districts <- 
  st_read(
    dsn = 
      file.path(
        "intermediate_data", 
        "CaAirDistrict.shp"
        )
  ) %>% 
  st_transform(crs = proj4string(asc_air_data))

save(
  air_districts, 
  file = 
    file.path(
      "intermediate_data",
      "air_districts.rdata"
      )
  )

# remove all objects from the environment
rm(list = ls(all.names = TRUE))

```


```{r air basin data}

# load asc air data to get crs
load(
  file = 
    file.path(
      "intermediate_data", 
      "asc_air_data.rdata"
    )
)

# unzip air district boundary data
unzip(
  zipfile = 
    file.path(
      "raw_data", 
      "california-air-resources-board-air-basin-boundaries.zip"
    ), 
  exdir = 
    file.path(
      "intermediate_data"
    )
  )

# read it into r
air_basins <- 
  st_read(
    dsn = 
      file.path(
        "intermediate_data", 
        "CaAirBasin.shp"
        )
  ) %>% 
  st_transform(crs = proj4string(asc_air_data))

save(
  air_basins, 
  file = 
    file.path(
      "intermediate_data",
      "air_basins.rdata"
      )
  )

# remove all objects from the environment
rm(list = ls(all.names = TRUE))

```


## california shapefile

```{r pull just california shapefile}

# load us shapefiles
load(
  file = 
    file.path(
      "raw_data", 
      "state_shapefiles.rdata"
    )
)

# load asc air data
load(
  file = 
    file.path(
      "intermediate_data", 
      "asc_air_data.rdata"
    )
)

# isolate california shapefile
california_shapefile <- 
  state_shapefiles %>% 
  filter(STUSPS == "CA") %>%  # get just california
  st_transform(crs = proj4string(asc_air_data))  # convert to pm2.5 coordinates

save(
  california_shapefile, 
  file = 
    file.path(
      "intermediate_data", 
      "california_shapefile.rdata"
    )
)

# remove all objects from the environment
rm(list = ls(all.names = TRUE))

```


## california shapefile and pm2.5

```{r clip air pollution data to shapefile}

# load california shapefile
load(
  file = 
    file.path(
      "intermediate_data", 
      "california_shapefile.rdata"
    )
)

# convert ca shapefile to raster-package-understandable
# SpatialPolygonsDataFrame
california_sp <- 
  as(california_shapefile, 
     'Spatial')

# load asc air data
load(
  file = 
    file.path(
      "intermediate_data", 
      "asc_air_data.rdata"
    )
)

# crop air data
air_cropped <- 
  raster::crop(
    asc_air_data, 
    california_sp) %>%  # crop air data to the bounding box
  raster::mask(california_sp)

# save cropped air data
save(
  air_cropped,
  file = 
    file.path(
      "intermediate_data", 
      "air_cropped.rdata"
    )
)

plot(air_cropped)

# remove all objects from the environment
rm(list = ls(all.names = TRUE))

```


## school data

```{r make county code name concordance from frpm data}

# load column name fixer
load(file = file.path("functions", "column_name_fixer.rdata"))

# read data 2018-19
free_reduced_lunch_from_raw <-
  readxl::read_excel(
    file.path(
      "raw_data", 
      "frpm1819.xlsx"), 
    sheet = 2, 
    skip = 1)

county_code_concordance <-
  free_reduced_lunch_from_raw %>% 
  column_name_fixer() %>% 
  select(county_name, county_code) %>% 
  unique()

save(county_code_concordance, 
     file = file.path("intermediate_data", 
                      "county_code_concordance.rdata"))

```


```{r read school enrollment data and save as .rdata files}

# make function to read them all into r from tab-delimited files
school_enrollment_tab_reader <- 
  function(start_year_numeric){
    
    end_year_chr <- 
      as.character(start_year_numeric + 1) %>% 
      substr(3, 4)  # get only the last two digits
    
    start_year_chr <- 
      as.character(start_year_numeric)
    
    file_name <- 
      str_c("school_enrollment_", 
            start_year_chr, 
            "_", 
            end_year_chr, 
            "_raw.txt")
      
    variable_name <- 
      str_c("school_enrollment_", 
            start_year_chr, 
            "_", 
            end_year_chr, 
            "_working_from_raw")
    
    read_tibble <- 
      read_delim(
        file = 
          file.path(
            "raw_data", 
            file_name),
        delim = "\t", 
        col_types = cols(.default = "?", CDS_CODE = col_character())
        )
    
    assign(variable_name, 
           read_tibble)
    
    save(
      list = variable_name, 
      file = 
        file.path(
          "intermediate_data", 
          str_c(
            variable_name, 
            ".rdata"
          )
        )
    )
    
    return(read_tibble)
  }

# make vector of starting years 2009-2018
start_years <- 
  seq(
    from = 2018,
    to = 2018, 
    by = 1
  )

# use function on all files
map(
  .f = school_enrollment_tab_reader, 
  .x = start_years
)

# # remove all objects from the environment
# rm(list = ls(all.names = TRUE))
  
```


```{r read english learner data and save as .rdata file}

# load column name fixer
load(file = file.path("functions", "column_name_fixer.rdata"))

# read in data
english_learner_from_raw <- 
  read_delim(file = file.path("raw_data", "fileselsch.txt"), 
             delim = "\t") 

# make dataset of english learner count
english_learners <- 
  english_learner_from_raw %>% 
  column_name_fixer() %>% 
  select(cds_code = cds, 
         language, 
         total_el) %>% 
  pivot_wider(names_from = language,  # make each row a school
              values_from = total_el, 
              values_fill = list(total_el = 0)) %>% 
  mutate(english_learners = rowSums(.[2:ncol(.)])) %>%  # get total enrollment
  select(cds_code, english_learners)

# save it
save(english_learners, 
     file = file.path("intermediate_data", 
                      "english_learners.rdata"))

# remove all objects from the environment
rm(list = ls(all.names = TRUE))

```


```{r read and save expense per pupil funding data}

# load column name fixer
load(file = file.path("functions", "column_name_fixer.rdata"))

# read data 2018-19
expense_per_pupil_from_raw <-
  readxl::read_excel(
    file.path(
      "raw_data", 
      "currentexpense1819.xlsx"), 
    sheet = 1, 
    skip = 10)

# make final set for inclusion into school dataset
expense_per_pupil <- 
  expense_per_pupil_from_raw %>% 
  column_name_fixer() %>% 
  select(cds_county_code_from_expense_per_pupil = co, 
         cds_district_code = cds, 
         district_from_expense_per_pupil = district, 
         cost_per_pupil = "current\r\nexpense_per_ada")

# save .rdata file to intermediate data
save(expense_per_pupil,
     file = file.path("intermediate_data", 
                      "expense_per_pupil.rdata"))

# # remove all objects from the environment
# rm(list = ls(all.names = TRUE))

```


```{r read and save school fte and teacher credential data}

# load column name fixer
load(file = file.path("functions", 
                      "column_name_fixer.rdata"))

# load county code concordance
load(file = file.path("intermediate_data", 
                      "county_code_concordance.rdata"))

# read in data
school_fte_from_raw <- 
  read_delim(file = file.path("raw_data", 
                              "StaffSchoolFTE18.txt"), 
             delim = "\t") 

# read in teacher credential data
teacher_credentials_from_raw <- 
  read_delim(file = file.path("raw_data", 
                              "StaffCred18.txt"), 
             delim = "\t") 

# better teacher credential data
teacher_credentials <- 
  teacher_credentials_from_raw %>% 
  column_name_fixer()
  
# calculate individual fte
individual_fte <- 
  school_fte_from_raw %>% 
  column_name_fixer() %>% 
  rename(district_code = districtcode, 
         school_code = schoolcode, 
         county_name = countyname) %>% 
  left_join(county_code_concordance, 
            by = "county_name") %>% 
  mutate(cds_code = paste0(district_code, school_code))
         
# count records with ftes <= 1
individual_fte %>% 
  filter(fte <= 1 & jobclassification %in% c(12, 26)) %>% 
  nrow()

individual_fte %>% 
  filter(fte <= 1) %>% 
  nrow()

# count records with ftes <= 1 that are duplicated
duplicated_recids <- individual_fte$recid[duplicated(individual_fte$recid)]

duplicated_low_fte_recids <- 
  individual_fte %>% 
  filter(fte <= 1 & recid %in% duplicated_recids) %>% 
  pull(recid)

fte_for_duplicated_recids <- 
  individual_fte %>% 
  filter(recid %in% duplicated_low_fte_recids) %>% 
  group_by(recid) %>% 
  summarize(total_fte = sum(fte), 
            count = n())

# check matches between teacher credentials and individual schools
recids_fte <- 
  individual_fte %>% 
  filter(stafftype == "T") %>% 
  pull(recid) %>% 
  unique()

# get recids
recids_fte <- sort(unique(individual_fte %>% filter(stafftype == "T") %>% pull(recid)))
recids_credentials <- sort(unique(teacher_credentials$recid))

length(recids_fte)
length(recids_credentials)

# ids in fte that are not in credentials
length(setdiff(recids_fte, recids_credentials))

# ids in credentials that are not in fte: none
length(setdiff(recids_credentials, recids_fte))

# count total rows and unique recids
nrow(individual_fte)
length(unique(individual_fte$recid))

# count number of records to be corrected
individual_fte %>% 
  filter(fte <= 1 & 
           jobclassification %in% c(12, 26) & 
           !(recid %in% duplicated_recids)) %>% 
  nrow()

# correct records where fte is <= to 1 by multiplying by 100       
individual_fte_corrected <- 
  individual_fte %>% 
  mutate(fte_corrected = ifelse(fte <= 1 & 
                                  jobclassification %in% c(12, 26) & 
                                  !(recid %in% duplicated_recids), 
                                fte*100, 
                                fte))
  
# total teacher fte by school
school_teacher_fte <- 
  individual_fte_corrected %>% 
  filter(stafftype == "T") %>%  # filter to teachers
  group_by(cds_code) %>% 
  summarise(fte_school = sum(fte_corrected)) %>% 
  mutate(teachers = fte_school/100)

################
# CREDENTIALIZE
################

# get recids and schools
teachers_and_schools <- 
  individual_fte %>% 
  filter(stafftype == "T") %>% 
  dplyr::select(cds_code, recid)

# combine teacher credentials with school
teacher_credentials_with_school <- 
  teacher_credentials %>% 
  left_join(teachers_and_schools, 
            by = "recid") %>% 
  dplyr::select(cds_code, 
                recid, 
                credentialtype, 
                authorizationtype) 

wide_teacher_credentials_with_school <- 
  teacher_credentials_with_school %>% 
  pivot_wider(names_from = credentialtype, 
              values_from = authorizationtype) 

# identify unique credentials
teacher_unique_credentials <- 
  teacher_credentials_with_school %>% 
  dplyr::select(-authorizationtype) %>% 
  mutate(indicator = 1) %>% 
  pivot_wider(names_from = credentialtype, 
              values_from = cds_code)

# check for missing recids after join
sum(is.na(teacher_credentials_with_school$cds_code))  # none! wow!

# make indicator for whether each teacher is fully credentialed
wide_teacher_credentials <-
  teacher_credentials %>% 
  dplyr::select(recid, credentialtype) %>% 
  unique() %>% 
  mutate(indicator = 1) %>% 
  pivot_wider(names_from = credentialtype,  # make each credential type a column
              values_from = indicator, 
              values_fill = list(indicator = 0))

# actually make the indicator variable
full_credential_teacher <- 
  wide_teacher_credentials %>% 
  mutate(full_cred = ifelse(`10` == 1, 1, 0)) %>%   # make indicator variable
  dplyr::select(recid, full_cred)

# now join with fte
fte_with_credential <-
  individual_fte_corrected %>% 
  left_join(full_credential_teacher, 
            by = "recid") %>% 
  filter(stafftype == "T") 

# count those with no credential status
sum(is.na(fte_with_credential$full_cred))  # 2093

# we'll call them zeroes for now
fte_credentialed <- 
  fte_with_credential %>% 
  mutate(full_cred_no_miss = 
           ifelse(is.na(full_cred) | 
                    full_cred == 0, 0, 1))

# percent of fte by credentialed and not!
percent_fte_credentialed_by_school <- 
  fte_credentialed %>% 
  group_by(cds_code, full_cred_no_miss) %>% 
  summarize(school_fte = sum(fte_corrected)) %>% 
  pivot_wider(names_from = full_cred_no_miss, 
              values_from = school_fte, 
              names_prefix = "cred_", 
              values_fill = list(school_fte = 0)) %>% 
  mutate(cred_percent = cred_1/(cred_0 + cred_1)) %>% 
  dplyr::select(cds_code, cred_percent)
  
mean(percent_fte_credentialed_by_school$cred_percent)

# save files
save(school_fte_from_raw, 
     file = file.path("intermediate_data", 
                      "school_fte_from_raw.rdata"))

save(individual_fte, 
     file = file.path("intermediate_data", 
                      "school_fte_from_raw.rdata"))

save(school_teacher_fte, 
     file = file.path("intermediate_data", 
                      "school_teacher_fte.rdata"))

save(teacher_credentials_from_raw, 
     file = file.path("intermediate_data", 
                      "teacher_credentials_from_raw.rdata"))

save(percent_fte_credentialed_by_school, 
     file = file.path("intermediate_data", 
                      "percent_fte_credentialed_by_school.rdata"))

# # remove all objects from the environment
# rm(list = ls(all.names = TRUE))

```


```{r read free and reduced price lunch data and save as .rdata files}

# load column name fixer
load(file = file.path("functions", "column_name_fixer.rdata"))

# read data 2018-19
free_reduced_lunch_from_raw <-
  readxl::read_excel(
    file.path(
      "raw_data", 
      "frpm1819.xlsx"), 
    sheet = 2, 
    skip = 1)

free_reduced_lunch <- 
  free_reduced_lunch_from_raw %>% 
  column_name_fixer() %>% 
  mutate(cds_code = paste0(county_code, district_code, school_code)) %>% 
  rename(free_lunch_percent = "percent_(%)_\r\neligible_free_\r\n(k-12)", 
         frpm_percent = "percent_(%)_\r\neligible_frpm_\r\n(k-12)") %>% 
  select(cds_code, 
         free_lunch_percent,
         frpm_percent)

# save .rdata file to intermediate data
save(free_reduced_lunch,
     file = file.path("intermediate_data", 
                      "free_reduced_lunch.rdata"))

# # remove all objects from the environment
# rm(list = ls(all.names = TRUE))

```


```{r read and save school addresses}

# fix parsing error in school addresses
public_school_directory_raw_text  <- 
  readLines(
    con =  
      file.path(
        "raw_data",
        "public_school_directory.txt"
        )
    )

public_school_directory_fixed_quotes <- 
  gsub(pattern = "\"350", 
       replace = "350", 
       x = public_school_directory_raw_text)

writeLines(
  public_school_directory_fixed_quotes, 
  con = 
    file.path(
      "raw_data",
      "public_school_directory_fixed.txt"
      )
  )

# read school addresses into tibble
public_school_directory_working_from_raw <-
  read_delim(file =
               file.path(
                 "raw_data",
                 "public_school_directory_fixed.txt"
                 ),
             delim = "\t", 
             col_types = cols(.default = "c", 
                              CDSCode = col_character())
             )

# save school addresses
save(
  public_school_directory_working_from_raw, 
  file = 
    file.path(
      "intermediate_data", 
      "public_school_directory_working_from_raw.rdata"
    )
)

# remove all objects from the environment
rm(list = ls(all.names = TRUE))

```


```{r read and save standardized testing data}

load(file = file.path("functions", "column_name_fixer.rdata"))

# unzip the english and language arts testing single data file
unzip(
  zipfile = 
    file.path(
      "raw_data", 
      "sb_ca2019_1_csv_v4.zip"
    ), 
  exdir = 
    file.path(
      "intermediate_data"
    )
  )

# unzip the science testing single data file
unzip(
  zipfile = 
    file.path(
      "raw_data", 
      "cast_ca2019_1_csv_v1.zip"
    ), 
  exdir = 
    file.path(
      "intermediate_data"
    )
  )

# read into tibbles
ela_testing_single_data_from_raw <-
  read_csv(file = file.path("intermediate_data",
                            "sb_ca2019_1_csv_v4.txt"), 
           col_types = cols(.default = "c"))

science_testing_single_data_from_raw <-
  read_csv(file = file.path("intermediate_data",
                            "cast_ca2019_1_csv_v1.txt"))

english_aggregate <- 
  ela_testing_single_data_from_raw %>% 
  column_name_fixer() %>% 
  filter(subgroup_id == "1") %>%   # only all student data, not subgrouped
  filter(test_id == "1") %>%  # only english
  mutate(cds_code = paste0(county_code, district_code, school_code)) %>% 
  filter(!(school_code == "0000000")) %>%  # take out districts
  filter(grade == "13") %>%  # all-student total
  select(cds_code,
         english_n_scores = total_tested_with_scores,
         english_standard_met = percentage_standard_met_and_above)

math_aggregate <- 
  ela_testing_single_data_from_raw %>% 
  column_name_fixer() %>% 
  filter(subgroup_id == "1") %>%   # only all student data, not subgrouped
  filter(test_id == "2") %>%  # only math
  mutate(cds_code = paste0(county_code, district_code, school_code)) %>% 
  filter(!(school_code == "0000000")) %>%  # take out districts
  filter(grade == "13") %>%  # all-student total 
  select(cds_code,
         math_n_scores = total_tested_with_scores,
         math_standard_met =  percentage_standard_met_and_above)

science_aggregate <- 
  science_testing_single_data_from_raw %>% 
  column_name_fixer() %>% 
  filter(demographic_id == "1") %>%   # only all student data, not subgrouped
  filter(test_id == "17") %>%  # science
  mutate(cds_code = paste0(county_code, district_code, school_code)) %>% 
  filter(!(school_code == "0000000")) %>%  # take out districts
  filter(grade == "13") %>%  # all-student total 
  select(cds_code,
         science_n_scores = total_number_tested_at_this_demographic_with_valid_scores,
         science_standard_met =  percentage_standard_met_and_above)

save(english_aggregate, 
     file = file.path("intermediate_data",
                      "english_aggregate.rdata"))

save(math_aggregate, 
     file = file.path("intermediate_data",
                      "math_aggregate.rdata"))

save(science_aggregate, 
     file = file.path("intermediate_data",
                      "science_aggregate.rdata"))

```



```{r read and save chronic absenteeism data}

# load column name fixer
load(file = file.path("functions", "column_name_fixer.rdata"))

# read into tibble
absentee_from_raw <-
  read_delim(file = file.path("raw_data", "chrabs1819.txt"), 
             delim = "\t", 
             col_types = "cccccccccccccc")

absentee <- absentee_from_raw %>% 
  column_name_fixer() %>% 
    filter(aggregatelevel == "S") %>%  # school-level data
  filter(reportingcategory == "TA") %>%  # pull ungrouped totals
  filter(charteryn == "All") %>%  # get all schools regardless of charter status
  mutate(cds_code = paste0(countycode, districtcode, schoolcode)) %>% 
  rename(chronic_absenteeism_rate = chronicabsenteeismrate) %>% 
  select(cds_code, chronic_absenteeism_rate)

save(absentee, 
     file = file.path("intermediate_data", 
                      "absentee.rdata"))

```



```{r read and save suspension data}

# load column name fixer
load(file = file.path("functions", "column_name_fixer.rdata"))

# read into tibble
suspensions_from_raw <-
  read_delim(file = file.path("raw_data", "susp1819.txt"), 
             delim = "\t", 
             col_types = "ccccccccccccccccccccc")

suspensions <- suspensions_from_raw %>% 
  column_name_fixer() %>% 
  filter(aggregatelevel == "S") %>%  # school-level data
  filter(reportingcategory == "TA") %>%  # pull ungrouped totals
  filter(charteryn == "All") %>%  # get all schools regardless of charter status
  mutate(cds_code = paste0(countycode, districtcode, schoolcode)) %>% 
  rename(suspension_rate = "suspension_rate_(total)") %>% 
  select(cds_code, 
         suspension_rate)

save(suspensions, 
     file = file.path("intermediate_data", 
                      "suspensions.rdata"))

```




```{r make school sf and non-sf files 2018-2019}

# load function to make variable names snake case
load(
  file = 
    file.path(
      "functions", 
      "column_name_fixer.rdata"
    )
)

# load relevant files
# 2018-19 enrollment
load(
  file = 
    file.path(
      "intermediate_data", 
      "school_enrollment_2018_19_working_from_raw.rdata"
    )
)

# school addresses
load(
  file = 
    file.path(
      "intermediate_data", 
      "public_school_directory_working_from_raw.rdata"
    )
)

# load air data file
load(
  file = 
    file.path(
      "intermediate_data", 
      "air_cropped.rdata"
    )
)

# fix variable names for school enrollment
school_enrollment_working <- 
  column_name_fixer(school_enrollment_2018_19_working_from_raw) %>%
   mutate(
     cds_school_code = str_sub(cds_code, 
                               start = -7), 
     
     )

# fix school enrollment data to eliminate nonpublic nonsec schools
school_enrollment_no_nonsec <- 
  school_enrollment_working %>% 
  filter(school != "Nonpublic, Nonsectarian Schools")

# public school directory
public_school_directory_working <- 
  column_name_fixer(public_school_directory_working_from_raw) %>% 
  rename(cds_code_dir = cdscode, 
         county_dir = county,
         district_dir = district,
         school_dir = school) %>% 
  # this isolates the individual school code
  mutate(cds_school_code_dir = str_sub(cds_code_dir,  
                                       start = -7))

# get unique schools in 2018-19
unique_schools <- 
  school_enrollment_working %>% 
  select(cds_code, 
         cds_school_code, 
         county, 
         district, 
         school) %>% 
  unique()  # each of these has a unique cds code

# get lat/longs from public school directory
school_directory_lat_long <- 
  public_school_directory_working %>% 
  dplyr::select(
    cds_code_dir, 
    cds_school_code_dir, 
    county_dir,
    district_dir,
    school_dir,
    latitude, 
    longitude
    )

# # check duplicates in cds code
# sum(table(school_directory_lat_long$cds_code_dir) - 1)  # should be 0
# sum(table(school_directory_lat_long$cds_school_code_dir) - 1)  # should be 0
# # note, this is not zero!  beware!

# get cds codes for schools 2018-19
schools_from_enroll <- 
  school_enrollment_working %>% 
  dplyr::select(
    cds_code, 
    cds_school_code, 
    county,
    district,
    school) %>% 
  unique()

# merge two
school_lat_long_first_try <- 
  schools_from_enroll %>% 
  left_join(school_directory_lat_long, 
            by = c("cds_code" =  "cds_code_dir"))

# filter missing latitudes and longitudes
school_lat_long_no_missing <- 
  school_lat_long_first_try %>% 
  filter(!is.na(latitude)) %>% 
  filter(!is.na(longitude)) %>% 
  filter(longitude != "No Data") %>% 
  mutate(latitude = as.numeric(latitude), 
         longitude = as.numeric(longitude))

# get cds codes of schools in 2018-19 dataset without lat_longs
cds_codes_no_lat_long <- 
  setdiff(
    unique(schools_from_enroll$cds_code), 
    unique(school_lat_long_no_missing$cds_code)
  )

# isolate schools with no lat/long
# (cds_code, cds_school_code, county, district, school)
schools_from_enroll_lat_long_missing <- 
  schools_from_enroll %>% 
  filter(cds_code %in% cds_codes_no_lat_long) 

# exclude nonpublic and nonsectarian schools
schools_from_enroll_lat_long_missing_no_nonsec <- 
  schools_from_enroll_lat_long_missing %>% 
  filter(!(school == "Nonpublic, Nonsectarian Schools"))

# find which schools missing lat/longs are in the directory
school_directory_no_lat_long <- 
  public_school_directory_working %>% 
  filter(cds_code_dir %in% cds_codes_no_lat_long)  # (two, these will be geocoded)

# match on cds code
schools_no_lat_long_matched_by_cds_school_code_only <- 
  left_join(
    schools_from_enroll_lat_long_missing_no_nonsec, 
    school_directory_lat_long, 
    by = c("cds_school_code" = "cds_school_code_dir")
    ) 

# pull long valley longitude
long_valley_longitude <- 
  schools_no_lat_long_matched_by_cds_school_code_only %>% 
  filter(cds_school_code == "6010763" &  # remove no-data long view record
           !(longitude == "No Data")) %>% 
  pull(longitude)

# pull long valley latitude
long_valley_latitude <- 
  schools_no_lat_long_matched_by_cds_school_code_only %>% 
  filter(cds_school_code == "6010763" &  # remove no-data long view record
           !(latitude == "No Data")) %>% 
  pull(latitude)
  
# make the replacement
schools_missing_lat_long_fixed <- 
  schools_no_lat_long_matched_by_cds_school_code_only %>% 
  # remove long view record that doesn't correspond to 18-19 data
  filter(!(cds_school_code == "6010763" &  
             latitude != "No Data")) %>% 
  mutate(man_longitude = ifelse(cds_school_code == "6010763", 
                                long_valley_longitude,
                                longitude), 
         man_latitude = ifelse(cds_school_code == "6010763", 
                               long_valley_latitude,
                               latitude)) %>% 
  select(c(cds_code,
           man_longitude, 
           man_latitude))  # remove latitude and longitude columns

# merge with prior dataset
schools_lat_long_merge <-
  school_lat_long_first_try %>%
  left_join(schools_missing_lat_long_fixed,
            by = "cds_code")

# make final school dataset
schools_lat_long_complete <-
  schools_lat_long_merge %>%
  # remove 397 nonpublic, nonsectarian schools
  filter(!(school == "Nonpublic, Nonsectarian Schools")) %>%
  mutate(longitude = ifelse(longitude == "No Data",
                            man_longitude,
                            longitude),
         longitude = ifelse(is.na(longitude),
                            man_longitude,
                            longitude),
         longitude = as.numeric(longitude),
         latitude = ifelse(latitude == "No Data",
                            man_latitude,
                            latitude),
         latitude = ifelse(is.na(latitude),
                            man_latitude,
                            latitude),
         latitude = as.numeric(latitude), 
         cds_county_code = substr(cds_code, 1, 2),
         cds_district_code = substr(cds_code, 3, 7)) %>%
  select(-c(district_dir,  # note that some of these differ
            school_dir,  # note that some of these differ
            man_longitude,
            man_latitude)) # drop directory and manual columns

# make into sf format for mapping
schools_sf <-
  st_as_sf(
    schools_lat_long_complete,
    coords =
      c("longitude",
        "latitude"),
    crs = st_crs(air_cropped))

# join school files with rest of data
school_enroll_sf <-
  right_join(
    schools_sf,
    school_enrollment_no_nonsec,
    by = c(
      "cds_code",
      "cds_school_code",
      "county",
      "district",
      "school"
      )
  )

# save created files
save(
  school_enrollment_no_nonsec,
  file =
    file.path(
      "intermediate_data",
      "school_enrollment_no_nonsec.rdata"
      )
  )

save(
  schools_missing_lat_long_fixed,
  file =
    file.path(
      "intermediate_data",
      "schools_missing_lat_long_fixed.rdata"
      )
  )

save(
  schools_sf,
  file =
    file.path(
      "intermediate_data",
      "schools_sf.rdata"
      )
  )

save(
  school_enroll_sf,
  file =
    file.path(
      "intermediate_data",
      "school_enroll_sf.rdata"
      )
  )

# # # remove all objects from the environment
# # rm(list = ls(all.names = TRUE))

```


## combining data types

```{r extract air values at schools}

# load air districts
load(
  file = 
    file.path(
      "intermediate_data", 
      "air_districts.rdata"
    )
)

# load air basins
load(
  file = 
    file.path(
      "intermediate_data", 
      "air_basins.rdata"
    )
)

# load pm2.5 estimates
load(
  file = 
    file.path(
      "intermediate_data", 
      "asc_air_data.rdata"
    )
)

# load schools
load(
  file =
    file.path(
      "intermediate_data",
      "schools_sf.rdata")
    )

# rename school thing
schools_to_get_air_sf <-
  schools_sf

# extract values of air data at schools
schools_to_get_air_sf$modeled_air_at_school <-
  raster::extract(asc_air_data,
                  schools_to_get_air_sf)

save(schools_to_get_air_sf, 
     file = file.path("intermediate_data", 
                      "schools_to_get_air_sf.rdata"))

# filter to nas
school_holdouts_to_get_air <- filter(schools_to_get_air_sf, 
                                     is.na(modeled_air_at_school))

# extract values for three that didn't get them the first time
school_holdouts_to_get_air$modeled_air_at_school <- 
  raster::extract(asc_air_data,
                  school_holdouts_to_get_air, 
                  buffer = 725,  # note: one has two values that get averaged
                  small = TRUE, 
                  fun = mean, 
                  na.rm = TRUE)

# add them back into the dataset
schools_with_air <- 
  schools_to_get_air_sf %>% 
  filter(!is.na(modeled_air_at_school)) %>% 
  rbind(school_holdouts_to_get_air)

# create new binary variable for pm2.5 over/under 12 ug/m3
schools_with_air <- 
  schools_with_air %>% 
  mutate(pm25_12_plus = ifelse(modeled_air_at_school > 12, "yes", "no"))

# detect the air district containing each school
school_air_district_no_basin_sf <- 
  schools_with_air %>% 
  st_join(
    air_districts["NAME"], 
    left = TRUE
    ) %>% 
  rename(air_district = NAME)

# investigate those without assignments
# one is in Nevada, the other is actually in the Bay Area
orphan_schools_no_air_district <- 
  school_air_district_no_basin_sf %>% 
  filter(is.na(air_district)) %>% 
  mutate(air_district = ifelse(county == "Solano", 
                               "Bay Area", 
                               NA))

# join them back
schools_with_air_districts <- 
  school_air_district_no_basin_sf %>% 
  filter(!is.na(air_district)) %>% 
  rbind(orphan_schools_no_air_district)

# detect the air basin containing each school
school_air_basin_district <- 
  schools_with_air_districts %>% 
  st_join(
    air_basins["NAME"],
    left = TRUE
    ) %>% 
  rename(air_basin = NAME)

# investigate those without assignments
orphan_schools_no_air_basin <- 
  school_air_basin_district %>% 
  filter(is.na(air_basin)) %>% 
  mutate(air_basin = ifelse(county == "Solano", 
                               "San Francisco Bay", 
                               NA))

# add them back
school_air_sf <- 
  school_air_basin_district %>% 
  filter(!is.na(air_basin)) %>% 
  rbind(orphan_schools_no_air_basin)

# save new sf with air at school
save(
  school_air_sf,
  file = file.path("intermediate_data",
                   "school_air_sf.rdata"))

# plot(air_cropped)
# plot(school_air_na, pch=16, cex=0.2, alpha = 0.8, col="black", add=TRUE)

# # make plot
# plot(school_air_sf["modeled_air_at_school"], pch=16, cex=0.4)

# # plot all 3!
# plot(air_cropped)
# plot(school_air_sf, pch=16, cex=0.2, alpha = 0.8, col="black", add=TRUE)
# plot(all_monitors_no_duplicates_sf, pch=16, cex=0.2, col="red", add=TRUE)
 
# # remove all objects from the environment
# rm(list = ls(all.names = TRUE))

```


```{r binning air basins}

# load school air
load(file = file.path("intermediate_data", 
                      "school_air_sf.rdata"))

# make air basin groups
northlands <- c("Lake County", 
                      "North Coast", 
                      "Northeast Plateau", 
                      "Mountain Counties", 
                      "Lake Tahoe")

southlands <- c("Great Basin Valleys", 
                      "Mojave Desert", 
                      "Salton Sea")

# Lake/County/North Coast further.  What would you think if we binned them with Northeast Plateau/Mountain Counties/Lake Tahoe

# add revised bins by air basin
school_air_sf_binned_basins <- 
  school_air_sf %>% 
  mutate(air_basin_binned = air_basin) %>% 
  mutate(air_basin_binned = if_else(air_basin_binned %in% northlands,
                                   "Northlands", 
                                   air_basin_binned)) %>%
  mutate(air_basin_binned = if_else(air_basin_binned %in% southlands,
                                    "Southlands", 
                                    air_basin_binned))

save(school_air_sf_binned_basins, 
     file = file.path("intermediate_data", 
                      "school_air_sf_binned_basins.rdata"))

```



```{r making the final dataset}

load(file = file.path("intermediate_data", 
                      "school_air_sf_binned_basins.rdata"))

load(file = file.path("intermediate_data",
                      "school_enrollment_no_nonsec.rdata"))

load(file = file.path("intermediate_data",
                      "absentee.rdata"))

load(file = file.path("intermediate_data",
                      "suspensions.rdata"))

load(file = file.path("intermediate_data",
                      "free_reduced_lunch.rdata"))

load(file = file.path("intermediate_data",
                      "english_aggregate.rdata"))

load(file = file.path("intermediate_data",
                      "math_aggregate.rdata"))

load(file = file.path("intermediate_data",
                      "science_aggregate.rdata"))

load(file = file.path("intermediate_data",
                      "english_learners.rdata"))

load(file = file.path("intermediate_data", 
                      "expense_per_pupil.rdata"))

load(file = file.path("intermediate_data", 
                      "school_teacher_fte.rdata"))

load(file = file.path("intermediate_data", 
                      "percent_fte_credentialed_by_school.rdata"))

# aggregate counts by ethnicity and gender
ethnicity_grade_by_school <- 
  school_enrollment_no_nonsec %>% 
  select(c(cds_code, 
           ethnic, 
           gender,
           enr_total)) %>% 
  mutate(ethnic_category = ethnic,  # make the ethnic categories meaningful
         ethnic_category =
           recode(
             ethnic_category,
             `0` = "not_reported",
             `1` = "american_indian_alaska_native_nh",
             `2` = "asian_nh",
             `3` = "pacific_islander_nh",
             `4` = "filipino_nh",
             `5` = "hispanic_latino",
             `6` = "african_american_nh",
             `7` = "white_nh",
             `9` = "two_plus_nh")) %>% 
  select(-c(ethnic)) %>% 
  pivot_wider(names_from = c(ethnic_category, gender),  # collect by school
              values_from = enr_total, 
              values_fill = list(enr_total = 0)) %>% 
  mutate(school_k_12_enrollment = rowSums(.[2:ncol(.)])) %>%   # get total enrollment
  select(cds_code, school_k_12_enrollment, sort(names(.)))  # sort columns

# make the final dataset
school_air_ethnicity_gender <- 
  school_air_sf_binned_basins %>% 
  left_join(ethnicity_grade_by_school, 
            by = "cds_code") %>% 
  select(-c(cds_school_code, 
            cds_school_code_dir, 
            county_dir))

school_all_covariates <- 
  school_air_ethnicity_gender %>% 
  left_join(absentee, by = "cds_code") %>% 
  left_join(suspensions, by = "cds_code") %>% 
  left_join(free_reduced_lunch, by = "cds_code") %>% 
  left_join(english_learners, by = "cds_code") %>% 
  left_join(expense_per_pupil, by = "cds_district_code") %>% 
  left_join(school_teacher_fte, by = "cds_code") %>% 
  left_join(percent_fte_credentialed_by_school, by = "cds_code")

save(school_all_covariates, 
     file = file.path("intermediate_data", 
                      "school_all_covariates.rdata"))

school_all_covariates_english <- 
  school_all_covariates %>% 
  left_join(english_aggregate, 
            by = "cds_code")

school_all_covariates_english_math <- 
  school_all_covariates_english %>% 
  left_join(math_aggregate, 
            by = "cds_code")

schools_all_data <- 
  school_all_covariates_english_math %>% 
  left_join(science_aggregate, 
            by = "cds_code")

save(schools_all_data, 
     file = file.path("intermediate_data", 
                      "schools_all_data.rdata"))

```


```{r calculating final values}

load(file = file.path("intermediate_data", 
                      "schools_all_data.rdata"))

full_data <- 
  schools_all_data %>% 
  mutate(percent_female = ((african_american_nh_F +
                             american_indian_alaska_native_nh_F +
                             asian_nh_F + 
                             filipino_nh_F +
                             hispanic_latino_F +
                             not_reported_F +
                             pacific_islander_nh_F +
                             two_plus_nh_F +
                             white_nh_F)/school_k_12_enrollment)*100,
         afr_am_percent = ((african_american_nh_F + 
                              african_american_nh_M)/
                             school_k_12_enrollment)*100, 
         aian_percent = ((american_indian_alaska_native_nh_F +
                            american_indian_alaska_native_nh_M)/
                             school_k_12_enrollment)*100, 
         asian_percent = ((asian_nh_F +
                            asian_nh_M)/
                            school_k_12_enrollment)*100, 
         filipino_percent = ((filipino_nh_F +
                            filipino_nh_M)/
                            school_k_12_enrollment)*100, 
         hisp_latinx_percent = ((hispanic_latino_F +
                            hispanic_latino_M)/
                            school_k_12_enrollment)*100, 
         pacific_islander_percent = ((pacific_islander_nh_F +
                            pacific_islander_nh_M)/
                            school_k_12_enrollment)*100, 
         white_percent  = ((white_nh_F +
                            white_nh_M)/
                            school_k_12_enrollment)*100, 
         two_plus_percent = ((two_plus_nh_F +
                            two_plus_nh_M)/
                            school_k_12_enrollment)*100,
         not_reported_percent = ((not_reported_F +
                            not_reported_M)/
                            school_k_12_enrollment)*100, 
         asian_filipino_percent = ((asian_nh_F +
                                         asian_nh_M +
                                         filipino_nh_F +
                                         filipino_nh_M)/
                                        school_k_12_enrollment)*100,
         aian_pi_percent = ((american_indian_alaska_native_nh_F +
                               american_indian_alaska_native_nh_M +
                               pacific_islander_nh_F +
                               pacific_islander_nh_M)/
                              school_k_12_enrollment)*100, 
         two_none_percent = ((two_plus_nh_F +
                                   two_plus_nh_M +
                                   not_reported_F +
                                   not_reported_M)/
                                  school_k_12_enrollment)*100,
         two_none_aian_pi_percent = ((two_plus_nh_F +
                                        two_plus_nh_M +
                                        not_reported_F +
                                        not_reported_M +
                                        american_indian_alaska_native_nh_F +
                                        american_indian_alaska_native_nh_M +
                                        pacific_islander_nh_F +
                                        pacific_islander_nh_M)/
                                       school_k_12_enrollment)*100,
         two_none_aian_pi_af_am_percent = ((two_plus_nh_F +
                                        two_plus_nh_M +
                                        not_reported_F +
                                        not_reported_M +
                                        american_indian_alaska_native_nh_F +
                                        american_indian_alaska_native_nh_M +
                                        pacific_islander_nh_F +
                                        pacific_islander_nh_M + 
                                        african_american_nh_F +
                                        african_american_nh_M)/
                                       school_k_12_enrollment)*100,
         not_white_latinx_percent = ((two_plus_nh_F +
                                        two_plus_nh_M +
                                        not_reported_F +
                                        not_reported_M +
                                        american_indian_alaska_native_nh_F +
                                        american_indian_alaska_native_nh_M +
                                        pacific_islander_nh_F +
                                        pacific_islander_nh_M + 
                                        african_american_nh_F +
                                        african_american_nh_M + 
                                        asian_nh_F +
                                        asian_nh_M +
                                        filipino_nh_F +
                                        filipino_nh_M)/
                                       school_k_12_enrollment)*100,
         pm25_12_plus = factor(pm25_12_plus), 
         chronic_absenteeism_rate = as.numeric(chronic_absenteeism_rate), 
         suspension_rate = as.numeric(suspension_rate), 
         free_lunch_percent = free_lunch_percent*100,
         frpm_percent = frpm_percent*100,
         english_learner_percent = english_learners/school_k_12_enrollment*100,
         student_teacher_ratio = school_k_12_enrollment/teachers,
         district_cost_per_pupil = cost_per_pupil,
         english_n_scores = as.numeric(english_n_scores), 
         english_standard_met = as.numeric(english_standard_met),
         math_n_scores = as.numeric(math_n_scores),
         math_standard_met = as.numeric(math_standard_met),
         science_n_scores = as.numeric(science_n_scores),
         science_standard_met = as.numeric(science_standard_met), 
         overall_standard_met = (english_standard_met +
                                   math_standard_met +
                                   science_standard_met)/3) %>%
  dplyr::select(-c(district_from_expense_per_pupil, 
            cds_county_code_from_expense_per_pupil))


full_data_analysis_variables <- 
  full_data %>% 
  dplyr::select(cds_code, 
         county, 
         district, 
         school, 
         cds_county_code, 
         cds_district_code, 
         modeled_air_at_school, 
         pm25_12_plus, 
         air_district, 
         air_basin, 
         air_basin_binned,
         school_k_12_enrollment, 
         percent_female, 
         afr_am_percent, 
         aian_percent, 
         asian_percent, 
         filipino_percent, 
         hisp_latinx_percent, 
         pacific_islander_percent, 
         white_percent, 
         two_plus_percent, 
         not_reported_percent,
         asian_filipino_percent,
         aian_pi_percent, 
         two_none_percent,
         two_none_aian_pi_percent,
         two_none_aian_pi_af_am_percent,
         not_white_latinx_percent,
         english_learners,
         english_learner_percent,
         chronic_absenteeism_rate, 
         suspension_rate, 
         frpm_percent, 
         fte_school,
         district_cost_per_pupil, 
         student_teacher_ratio,
         cred_percent,
         english_n_scores, 
         english_standard_met, 
         math_n_scores, 
         math_standard_met, 
         science_n_scores, 
         science_standard_met, 
         overall_standard_met) %>% 
  st_drop_geometry()

save(full_data, 
     file = file.path("intermediate_data", 
                      "full_data.rdata"))

save(full_data_analysis_variables, 
     file = file.path("intermediate_data", 
                      "full_data_analysis_variables.rdata"))

dataset_full <- 
  full_data_analysis_variables

save(dataset_full, 
     file = file.path("dataset_full.rdata"))

```



```{r checking missings}

# load file
load(file = file.path("dataset_full.rdata"))

# check NA counts
sum(is.na(dataset_full$overall_standard_met))
sum(is.na(dataset_full$pm25_12_plus))
sum(is.na(dataset_full$modeled_air_at_school))
sum(is.na(dataset_full$air_district))
sum(is.na(dataset_full$air_basin))

sum(is.na(dataset_full$overall_standard_met))
sum(is.na(dataset_full$afr_am_percent))
sum(is.na(dataset_full$aian_percent))
sum(is.na(dataset_full$asian_percent))
sum(is.na(dataset_full$filipino_percent))
sum(is.na(dataset_full$hisp_latinx_percent))
sum(is.na(dataset_full$pacific_islander_percent))
sum(is.na(dataset_full$white_percent))
sum(is.na(dataset_full$two_plus_percent))
sum(is.na(dataset_full$not_reported_percent))

sum(is.na(dataset_full$english_learner_percent))
sum(is.na(dataset_full$frpm_percent))
sum(is.na(dataset_full$district_cost_per_pupil))
sum(is.na(dataset_full$student_teacher_ratio))
sum(is.na(dataset_full$english_standard_met))
sum(is.na(dataset_full$math_standard_met))
sum(is.na(dataset_full$science_standard_met))


# drop zero-enrollment school (one, now count 10130)
schools_with_enrollment <- 
  dataset_full %>% 
  filter(school_k_12_enrollment != 0)


# check NA counts
sum(is.na(schools_with_enrollment$overall_standard_met))
sum(is.na(schools_with_enrollment$pm25_12_plus))
sum(is.na(schools_with_enrollment$modeled_air_at_school))
sum(is.na(schools_with_enrollment$air_district))
sum(is.na(schools_with_enrollment$air_basin))

sum(is.na(schools_with_enrollment$overall_standard_met))
sum(is.na(schools_with_enrollment$afr_am_percent))
sum(is.na(schools_with_enrollment$aian_percent))
sum(is.na(schools_with_enrollment$asian_percent))
sum(is.na(schools_with_enrollment$filipino_percent))
sum(is.na(schools_with_enrollment$hisp_latinx_percent))
sum(is.na(schools_with_enrollment$pacific_islander_percent))
sum(is.na(schools_with_enrollment$white_percent))
sum(is.na(schools_with_enrollment$two_plus_percent))
sum(is.na(schools_with_enrollment$not_reported_percent))

sum(is.na(schools_with_enrollment$english_learner_percent))
sum(is.na(schools_with_enrollment$frpm_percent))
sum(is.na(schools_with_enrollment$district_cost_per_pupil))
sum(is.na(schools_with_enrollment$student_teacher_ratio))
sum(is.na(schools_with_enrollment$english_standard_met))
sum(is.na(schools_with_enrollment$math_standard_met))
sum(is.na(schools_with_enrollment$science_standard_met))

# drop schools without complete outcome data
schools_with_math <- 
  dataset_full %>% 
  filter(!is.na(math_standard_met))

nrow(schools_with_math)

# check NA counts
sum(is.na(schools_with_math$overall_standard_met))
sum(is.na(schools_with_math$pm25_12_plus))
sum(is.na(schools_with_math$modeled_air_at_school))
sum(is.na(schools_with_math$air_district))
sum(is.na(schools_with_math$air_basin))

sum(is.na(schools_with_math$overall_standard_met))
sum(is.na(schools_with_math$afr_am_percent))
sum(is.na(schools_with_math$aian_percent))
sum(is.na(schools_with_math$asian_percent))
sum(is.na(schools_with_math$filipino_percent))
sum(is.na(schools_with_math$hisp_latinx_percent))
sum(is.na(schools_with_math$pacific_islander_percent))
sum(is.na(schools_with_math$white_percent))
sum(is.na(schools_with_math$two_plus_percent))
sum(is.na(schools_with_math$not_reported_percent))

sum(is.na(schools_with_math$english_learner_percent))
sum(is.na(schools_with_math$frpm_percent))
sum(is.na(schools_with_math$district_cost_per_pupil))
sum(is.na(schools_with_math$student_teacher_ratio))
sum(is.na(schools_with_math$english_standard_met))
sum(is.na(schools_with_math$math_standard_met))
sum(is.na(schools_with_math$science_standard_met))

# complete cases dataset
dataset_complete_cases_all_data <- 
  schools_with_math %>% 
  filter(!is.na(english_learner_percent)) %>% 
  filter(!is.na(district_cost_per_pupil)) %>% 
  filter(!is.na(student_teacher_ratio)) %>% 
  filter(!is.na(air_basin_binned))

nrow(dataset_complete_cases_all_data)  # 8838 schools

# check NA counts
sum(is.na(dataset_complete_cases_all_data$overall_standard_met))
sum(is.na(dataset_complete_cases_all_data$pm25_12_plus))
sum(is.na(dataset_complete_cases_all_data$modeled_air_at_school))
sum(is.na(dataset_complete_cases_all_data$air_district))
sum(is.na(dataset_complete_cases_all_data$air_basin))

sum(is.na(dataset_complete_cases_all_data$overall_standard_met))
sum(is.na(dataset_complete_cases_all_data$afr_am_percent))
sum(is.na(dataset_complete_cases_all_data$aian_percent))
sum(is.na(dataset_complete_cases_all_data$asian_percent))
sum(is.na(dataset_complete_cases_all_data$filipino_percent))
sum(is.na(dataset_complete_cases_all_data$hisp_latinx_percent))
sum(is.na(dataset_complete_cases_all_data$pacific_islander_percent))
sum(is.na(dataset_complete_cases_all_data$white_percent))
sum(is.na(dataset_complete_cases_all_data$two_plus_percent))
sum(is.na(dataset_complete_cases_all_data$not_reported_percent))

sum(is.na(dataset_complete_cases_all_data$english_learner_percent))
sum(is.na(dataset_complete_cases_all_data$frpm_percent))
sum(is.na(dataset_complete_cases_all_data$district_cost_per_pupil))
sum(is.na(dataset_complete_cases_all_data$student_teacher_ratio))
sum(is.na(dataset_complete_cases_all_data$english_standard_met))
sum(is.na(dataset_complete_cases_all_data$math_standard_met))
sum(is.na(dataset_complete_cases_all_data$science_standard_met))

# remove unneeded variables
colnames(dataset_complete_cases_all_data)

dataset_complete_cases <- 
  dataset_complete_cases_all_data %>% 
  dplyr::select(cds_code, 
         math_standard_met,
         modeled_air_at_school,
         pm25_12_plus, 
         air_basin,
         air_basin_binned,
         air_district,
         afr_am_percent, 
         asian_filipino_percent, 
         two_none_aian_pi_percent, 
         hisp_latinx_percent, 
         two_none_aian_pi_af_am_percent,
         not_white_latinx_percent,
         white_percent, 
         english_learner_percent, 
         frpm_percent, 
         district_cost_per_pupil, 
         student_teacher_ratio, 
         cred_percent,
         school_k_12_enrollment)

dataset_complete_cases_forget_funding <- 
  schools_with_math %>% 
  filter(!is.na(english_learner_percent)) %>% 
  filter(!is.na(student_teacher_ratio)) %>% 
  filter(!is.na(air_district)) %>% 
  dplyr::select(cds_code, 
         math_standard_met,
         pm25_12_plus, 
         modeled_air_at_school,
         air_basin,
         air_basin_binned,
         air_district,
         afr_am_percent, 
         asian_filipino_percent, 
         two_none_aian_pi_percent, 
         hisp_latinx_percent, 
         two_none_aian_pi_af_am_percent,
         not_white_latinx_percent,
         white_percent, 
         english_learner_percent, 
         frpm_percent, 
         district_cost_per_pupil, 
         student_teacher_ratio, 
         cred_percent,
         school_k_12_enrollment)
  
save(dataset_complete_cases, 
     file = file.path("dataset_complete_cases.rdata"))

save(dataset_complete_cases_forget_funding, 
     file = file.path("dataset_complete_cases_forget_funding.rdata"))

nrow(dataset_complete_cases_forget_funding)

nrow(schools_with_math)

```


```{r preliminary data analysis, eval=FALSE, include=FALSE}

expression(paste("Mean PM"["2.5"]," concentration (",mu,"g/m"^"3",") in 2018"))

# make plots

# histogram for test scores
ggplot(data = data_for_table_one, 
       aes(x = `Overall mean of standards met or exceeded (%)`)) +
  geom_histogram(binwidth = 1) +
  xlab("Mean percentage of students who met or exceeded standard across \nEnglish, science, and math in 2018-19") +
  ylab("Count")

# histogram for air pollution
ggplot(data = causal_inference_preliminary_dataset, 
       aes(x = modeled_air_at_school)) +
  geom_histogram(binwidth = 0.1) +
  xlab(expression(paste("Mean PM"["2.5"]," concentration (",mu,"g/m"^"3",") in 2018"))) +
  ylab("Count")

# make basic scatterplot with line through it
ggplot(data = causal_inference_preliminary_dataset, 
       aes(x = modeled_air_at_school, 
           y = overall_standard_met)) +
  geom_point(color = "blue", alpha = 0.5) +
  geom_smooth(method=loess, 
              se=TRUE, 
              color="darkred") +
  xlab(expression(paste("Mean PM"["2.5"]," concentration (",mu,"g/m"^"3",") in 2018"))) +
  ylab("Mean Percentage of Students Who Met or Exceeded Standard \n(English, Science, and Math) in 2018-19")

# get basic summary statistics
mean(causal_inference_preliminary_dataset$overall_standard_met)
summary(causal_inference_preliminary_dataset$overall_standard_met)
sd(causal_inference_preliminary_dataset$overall_standard_met)



load(file = file.path( "causal_inference_preliminary_dataset.rdata"))

load(file = file.path("intermediate_data", "air_cropped.rdata"))

# plot air data
plot(air_cropped)

dev.off()

load(file = file.path("intermediate_data", "california_shapefile.rdata"))

# make plot of modeled air at each school
plot.new()

plot(california_shapefile[1], main=NULL, color=rgb(1, 1, 1, alpha = 1), border = "black", add=TRUE)
plot(causal_inference_preliminary_dataset["modeled_air_at_school"], pch=16, cex=0.4, 
     xlab=NULL, ylab=NULL, main=NULL)
title(main = expression(paste("Mean PM"["2.5"]," concentration (",mu,"g/m"^"3",") in 2018")))

# plot test scores
plot(causal_inference_preliminary_dataset["overall_standard_met"], pch=16, cex=0.4, 
     xlab=NULL, ylab=NULL, main=NULL, pal=brewer.pal(10, "RdYlGn"))

mean(causal_inference_preliminary_dataset$modeled_air_at_school)
sd(causal_inference_preliminary_dataset$modeled_air_at_school)

```

